# ═══════════════════════════════════════════════════════════════════
# Jarvis — Environment Configuration
# ═══════════════════════════════════════════════════════════════════
# Copy this file to `.env` and fill in your values.
#   cp .env.example .env
# ═══════════════════════════════════════════════════════════════════

# ─── LLM Provider ───────────────────────────────────────────────
# Which LLM backend to use: "ollama" | "gemini" | "grok"
LLM_PROVIDER=gemini

# ─── Ollama (Local) ─────────────────────────────────────────────
OLLAMA_URL=http://localhost:11434/api/generate
OLLAMA_MODEL=gemma:2b

# ─── Google Gemini ───────────────────────────────────────────────
# Get your key: https://aistudio.google.com/apikey
GEMINI_API_KEY=your-gemini-api-key-here
GEMINI_MODEL=gemini-2.0-flash

# ─── xAI Grok ───────────────────────────────────────────────────
# Get your key: https://console.x.ai/
GROK_API_KEY=your-grok-api-key-here
GROK_MODEL=grok-3-mini-fast

# ─── Wake Word (Porcupine) ──────────────────────────────────────
PORCUPINE_ACCESS_KEY=your-porcupine-key-here
PORCUPINE_MODEL_PATH=
