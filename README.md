<p align="center">
  <h1 align="center">ğŸ§  Jarvis</h1>
  <p align="center">
    <strong>Autonomous AI Assistant for Windows</strong>
  </p>
  <p align="center">
    Voice-controlled Â· Multi-LLM Â· Shell Execution Â· Real-time TTS
  </p>
  <p align="center">
    <a href="#quickstart">Quickstart</a> â€¢
    <a href="#features">Features</a> â€¢
    <a href="#architecture">Architecture</a> â€¢
    <a href="#configuration">Configuration</a> â€¢
    <a href="#commands">Commands</a> â€¢
    <a href="#contributing">Contributing</a>
  </p>
</p>

---

## What is Jarvis?

Jarvis is a **desktop AI assistant** that listens to your voice, understands natural language, executes system commands, and speaks back â€” all running natively on Windows with a PyQt6 interface.

Unlike chatbots that just *talk about* doing things, Jarvis **actually does them**. Say *"create a folder called Projects"* and it runs the PowerShell command. Ask *"what's running on port 3000?"* and it checks for you.

```
You:     "Hey Jarvis, list all Python files in Downloads"
Jarvis:  Here are your Python files.
         [EXEC] Get-ChildItem $env:USERPROFILE\Downloads -Filter *.py
         > script.py  main.py  utils.py
```

---

## Features

| Feature | Description |
|---|---|
| ğŸ™ï¸ **Voice Interface** | Wake word detection ("Jarvis") via Porcupine + real-time speech-to-text via Faster-Whisper |
| ğŸ§  **Multi-LLM Brain** | Switch between **Groq**, **Gemini**, **Grok**, or local **Ollama** â€” at runtime |
| âš¡ **Shell Execution** | AI-generated PowerShell commands are auto-extracted and executed safely |
| ğŸ”Š **Text-to-Speech** | Natural voice responses via Edge-TTS (Microsoft neural voices) |
| ğŸ›¡ï¸ **Safety Guards** | Dangerous commands (`format`, `rm -rf`, `diskpart`) are blocked automatically |
| ğŸ”„ **Provider Failover** | If one LLM is down or rate-limited, Jarvis auto-switches to another |
| ğŸ’¬ **Conversation Memory** | Sliding-window context (20 messages) for multi-turn conversations |
| ğŸ¨ **Colored Terminal** | Semantic coloring â€” cyan for input, green for AI, yellow for commands, magenta for output |
| ğŸ–¥ï¸ **Desktop UI** | PyQt6 window with embedded terminal, thinking orb, and system tray |
| ğŸ“¦ **One-Click Launch** | `run_jarvis.bat` handles venv, dependencies, and env setup automatically |

---

## Quickstart

### Prerequisites

- **Python 3.10+** â€” [Download](https://python.org/downloads/)
- **API Key** (at least one):
  - [Groq](https://console.groq.com/keys) (free, fastest) â† **recommended**
  - [Gemini](https://aistudio.google.com/apikey) (free tier available)
  - [Ollama](https://ollama.com) (fully local, no API key needed)

### Setup (3 steps)

```powershell
# 1. Clone and enter the project
git clone https://github.com/your-username/Antigravity.git
cd Antigravity

# 2. Create virtual environment and install dependencies
python -m venv .venv
.venv\Scripts\activate
pip install -r Jarvis\requirements.txt

# 3. Configure your API key
copy .env.example .env
notepad .env          # Paste your API key, set LLM_PROVIDER
```

### Run

```powershell
.\run_jarvis.bat
```

Or manually:
```powershell
.venv\Scripts\activate
python -m Jarvis.main
```

---

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Jarvis App                          â”‚
â”‚                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Listener â”‚â”€â”€â”€â–¶â”‚ Orchestrator â”‚â”€â”€â”€â–¶â”‚    Brain      â”‚   â”‚
â”‚  â”‚ (Voice)  â”‚    â”‚  (Router)    â”‚â—€â”€â”€â”€â”‚ (Multi-LLM)   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚              â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚       â”‚          â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚     â–²  â–²  â–²  â–²        â”‚
â”‚       â”‚          â”‚  â”‚ Tools  â”‚  â”‚     â”‚  â”‚  â”‚  â”‚         â”‚
â”‚       â”‚          â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚     â”‚  â”‚  â”‚  â”” Ollama  â”‚
â”‚       â”‚          â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚     â”‚  â”‚  â””â”€â”€ Grok     â”‚
â”‚       â”‚          â”‚  â”‚ Shell  â”‚  â”‚     â”‚  â””â”€â”€â”€â”€â”€ Gemini   â”‚
â”‚       â”‚          â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€ Groq     â”‚
â”‚       â–¼          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚
â”‚  â”‚  STT     â”‚    â”‚     TTS      â”‚                        â”‚
â”‚  â”‚(Whisper) â”‚    â”‚  (Edge-TTS)  â”‚                        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
â”‚                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚              PyQt6 UI (Window + Tray)             â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Project Structure

```
Antigravity/
â”œâ”€â”€ run_jarvis.bat              # One-click launcher
â”œâ”€â”€ .env                        # API keys & config (git-ignored)
â”œâ”€â”€ .env.example                # Reference config template
â”‚
â””â”€â”€ Jarvis/
    â”œâ”€â”€ main.py                 # App entry point â€” wires everything together
    â”œâ”€â”€ config.py               # Environment loading & constants
    â”œâ”€â”€ requirements.txt        # Python dependencies
    â”‚
    â”œâ”€â”€ core/
    â”‚   â”œâ”€â”€ brain.py            # Multi-provider LLM interface (Groq/Gemini/Grok/Ollama)
    â”‚   â”œâ”€â”€ orchestrator.py     # Command router & shell executor
    â”‚   â”œâ”€â”€ tools.py            # Sandboxed file system operations
    â”‚   â””â”€â”€ colors.py           # Terminal color utilities
    â”‚
    â”œâ”€â”€ input/
    â”‚   â”œâ”€â”€ listener.py         # Autonomous voice listener (wake word + recording)
    â”‚   â”œâ”€â”€ audio_capture.py    # Microphone audio capture
    â”‚   â””â”€â”€ transcribe_worker.py # Faster-Whisper STT worker thread
    â”‚
    â”œâ”€â”€ output/
    â”‚   â”œâ”€â”€ tts.py              # Edge-TTS text-to-speech
    â”‚   â””â”€â”€ visuals.py          # Thinking orb animation
    â”‚
    â”œâ”€â”€ ui/
    â”‚   â”œâ”€â”€ window.py           # Main PyQt6 window
    â”‚   â””â”€â”€ tray.py             # System tray icon & menu
    â”‚
    â””â”€â”€ tests/
        â””â”€â”€ test_orchestrator.py # Unit tests for command routing
```

---

## Configuration

All configuration is done via the `.env` file in the project root:

| Variable | Description | Default |
|---|---|---|
| `LLM_PROVIDER` | Active LLM backend | `ollama` |
| `GROQ_API_KEY` | Groq Cloud API key | â€” |
| `GROQ_MODEL` | Groq model name | `llama-3.3-70b-versatile` |
| `GEMINI_API_KEY` | Google Gemini API key | â€” |
| `GEMINI_MODEL` | Gemini model name | `gemini-2.0-flash` |
| `GROK_API_KEY` | xAI Grok API key | â€” |
| `GROK_MODEL` | Grok model name | `grok-3-mini-fast` |
| `OLLAMA_URL` | Ollama API endpoint | `http://localhost:11434/api/generate` |
| `OLLAMA_MODEL` | Ollama model name | `gemma:2b` |
| `PORCUPINE_ACCESS_KEY` | Picovoice wake word key | â€” |
| `TTS_VOICE` | Edge-TTS voice ID | `en-US-GuyNeural` |

### Provider Comparison

| Provider | Speed | Intelligence | Cost | Needs Internet |
|---|---|---|---|---|
| **Groq** | âš¡ Fastest | ğŸ§ ğŸ§ ğŸ§  (Llama 3.3 70B) | Free tier | Yes |
| **Gemini** | Fast | ğŸ§ ğŸ§ ğŸ§  (Flash) | Free tier | Yes |
| **Grok** | Fast | ğŸ§ ğŸ§ ğŸ§  (xAI) | Paid | Yes |
| **Ollama** | Varies | ğŸ§  (depends on model) | Free | No |

---

## Commands

### Voice Commands
Just say **"Jarvis"** followed by your request:
- *"Jarvis, what time is it?"*
- *"Jarvis, open notepad"*
- *"Jarvis, list files in my Downloads"*
- *"Jarvis, create a folder called Projects"*
- *"Jarvis, how much RAM am I using?"*

### Brain Control Commands
Type or say these to manage the LLM at runtime:

```
llm status                    â€” Show provider, model, and health
llm models                    â€” List available models
llm provider <name>           â€” Switch provider (groq/gemini/grok/ollama)
llm use <model>               â€” Switch model
llm set temperature <0..2>    â€” Adjust creativity
llm set max_tokens <int>      â€” Set response length limit
llm set timeout <seconds>     â€” Set request timeout
llm prompt show               â€” View system prompt
llm prompt set <text>         â€” Override system prompt
llm reset                     â€” Reset all settings to defaults
clear memory                  â€” Clear conversation history
```

### Direct Shell Commands
These bypass the LLM and execute directly:
```
dir                           â€” List directory contents
git status                    â€” Check git status
pip list                      â€” List Python packages
ipconfig                      â€” Show network config
tasklist                      â€” List running processes
python script.py              â€” Run a Python script
```

---

## Terminal Color Scheme

| Color | Meaning | Tag |
|---|---|---|
| ğŸ”µ **Bright Cyan** | Your input (voice/typed) | `[YOU]` |
| ğŸŸ¢ **Bright Green** | AI responses | `[JARVIS]` |
| ğŸŸ¡ **Bright Yellow** | Shell commands being executed | `[EXEC]` |
| ğŸŸ£ **Magenta** | Shell command output | *(raw output)* |
| ğŸ”´ **Bright Red** | Errors | `[ERROR]` |
| ğŸ”µ **Bright Blue** | System info | `[INFO]` |
| âšª **Dark Gray** | Debug/timing info | *(dimmed)* |

---

## How It Works

1. **Listener** detects the wake word "Jarvis" via Porcupine
2. **Audio Capture** records your voice until silence is detected
3. **Faster-Whisper** transcribes the audio to text locally
4. **Orchestrator** classifies the intent:
   - Is it a shell command? â†’ Execute directly in PowerShell
   - Is it a brain meta-command? â†’ Adjust settings
   - Otherwise â†’ Send to the **Brain** (LLM)
5. **Brain** generates a response, possibly containing `[SHELL]...[/SHELL]` tags
6. **Orchestrator** extracts and executes any shell commands, with safety checks
7. **TTS** converts the response to speech via Edge-TTS
8. **UI** displays everything in the embedded terminal with color coding

---

## Safety

Jarvis includes safety guards for commands generated by the LLM:

**Blocked commands** (auto-detected):
- `format c:` â€” Drive formatting
- `rm -rf` / `Remove-Item -Recurse` â€” Recursive deletion
- `diskpart` â€” Disk partitioning
- `bcdedit` â€” Boot config changes
- `reg delete` â€” Registry deletion
- `shutdown` â€” System shutdown

If a dangerous command is detected, Jarvis will block it and display a warning instead of executing it.

---

## Development

### Running Tests
```powershell
.venv\Scripts\python.exe -m unittest Jarvis.tests.test_orchestrator -v
```

### Testing the Brain Directly
```python
from Jarvis.core.brain import Brain
brain = Brain()
response = brain.generate_response("Hello, what can you do?")
print(response)
```

### Switching Providers Programmatically
```python
from Jarvis.core.brain import Brain
brain = Brain(provider="groq")       # Start with Groq
brain.set_provider("gemini")          # Switch to Gemini
brain.set_model("gemini-2.0-flash")   # Change model
```

---

## Tech Stack

| Component | Technology |
|---|---|
| Language | Python 3.10+ |
| Desktop UI | PyQt6 |
| Wake Word | Porcupine (Picovoice) |
| Speech-to-Text | Faster-Whisper (local) |
| Text-to-Speech | Edge-TTS (Microsoft Neural) |
| LLM Providers | Groq Â· Gemini Â· Grok Â· Ollama |
| Shell | PowerShell (Windows native) |
| Config | python-dotenv |

---

## Roadmap

- [ ] Streaming LLM responses (token-by-token display)
- [ ] Multi-step task execution (chained commands)
- [ ] Function calling / tool use via LLM APIs
- [ ] Plugin system for extensible tools
- [ ] Cross-platform support (macOS / Linux)
- [ ] WebSocket-based remote access
- [ ] Conversation persistence (save/load sessions)

---

## License

This project is proprietary. All rights reserved.

---

<p align="center">
  Built with focus and intention.
</p>
