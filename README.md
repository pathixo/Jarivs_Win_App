<p align="center">
  <h1 align="center">ğŸ§  Jarvis</h1>
  <p align="center">
    <strong>Autonomous Voice-Driven Coding Engine for Windows</strong>
  </p>
  <p align="center">
    Voice-controlled Â· Multi-LLM Â· Shell Execution Â· Persona System Â· Real-time TTS
  </p>
  <p align="center">
    <a href="#quickstart">Quickstart</a> â€¢
    <a href="#features">Features</a> â€¢
    <a href="#architecture">Architecture</a> â€¢
    <a href="#local-llm-models">Models</a> â€¢
    <a href="#persona-system">Personas</a> â€¢
    <a href="#commands">Commands</a> â€¢
    <a href="#roadmap">Roadmap</a>
  </p>
</p>

---

## What is Jarvis?

Jarvis is a **desktop AI assistant** that listens to your voice, understands natural language, executes system commands, and speaks back â€” all running natively on Windows with a PyQt6 interface.

Unlike chatbots that just *talk about* doing things, Jarvis **actually does them**. Say *"create a folder called Projects"* and it runs the PowerShell command. Ask *"what's running on port 3000?"* and it checks for you.

```
You:     "Hey Jarvis, list all Python files in Downloads"
Jarvis:  Here are your Python files.
         [EXEC] Get-ChildItem $env:USERPROFILE\Downloads -Filter *.py
         > script.py  main.py  utils.py
```

---

## Project Status

> **Last updated:** February 2026

### What's Built

| Module | File | Status | Description |
|---|---|---|---|
| **Core Brain** | `core/brain.py` | âœ… Complete | Multi-provider LLM (Ollama, Gemini, Groq, Grok) with retry, failover, and memory |
| **Orchestrator** | `core/orchestrator.py` | âœ… Complete | Command routing, shell execution, safety checks, meta-commands |
| **Persona System** | `core/personas.py` | âœ… **NEW** | 5 switchable personalities with matched voices |
| **Tools** | `core/tools.py` | âœ… Complete | Sandboxed file system operations |
| **TTS** | `output/tts.py` | âœ… Complete | Edge-TTS with dynamic voice switching per persona |
| **Listener** | `input/listener.py` | âœ… Complete | Wake word (Porcupine) + STT (Faster-Whisper) pipeline |
| **UI** | `ui/window.py` | âœ… Complete | PyQt6 GUI with thinking orb, terminal, command input panel |
| **Tray** | `ui/tray.py` | âœ… Complete | System tray with show/hide, pause/resume, quit |
| **Tests** | `tests/test_orchestrator.py` | âœ… 19 passing | Full coverage: commands, personas, voices, safety |

---

## Features

| Feature | Description |
|---|---|
| ğŸ™ï¸ **Voice Interface** | Wake word detection ("Jarvis") via Porcupine + real-time speech-to-text via Faster-Whisper |
| ğŸ§  **Multi-LLM Brain** | Switch between **Groq**, **Gemini**, **Grok**, or local **Ollama** â€” at runtime |
| âš¡ **Shell Execution** | AI-generated PowerShell commands are auto-extracted and executed safely |
| ğŸ”Š **Text-to-Speech** | Natural voice responses via Edge-TTS (Microsoft neural voices) |
| ğŸ­ **Persona System** | 5 built-in personalities (Witty, Professional, Friendly, Technical, Comic) with matched voices |
| ğŸ›¡ï¸ **Safety Guards** | Dangerous commands (`format`, `rm -rf`, `diskpart`) are blocked automatically |
| ğŸ”„ **Provider Failover** | If one LLM is down or rate-limited, Jarvis auto-switches to another |
| ğŸ’¬ **Conversation Memory** | Sliding-window context (20 messages) for multi-turn conversations |
| ğŸ¨ **Colored Terminal** | Semantic coloring â€” cyan for input, green for AI, yellow for commands, magenta for output |
| ğŸ–¥ï¸ **Desktop UI** | PyQt6 window with embedded terminal, thinking orb, command input, and system tray |
| âŒ¨ï¸ **Type or Talk** | Use the GUI command input bar *or* voice â€” both go through the same pipeline |
| ğŸ“¦ **One-Click Launch** | `run_jarvis.bat` handles venv, dependencies, and env setup automatically |

---

## Local LLM Models

Jarvis uses **Ollama** for local-first LLM inference. All models are tested and working:

### Benchmarks (tested on local hardware)

| Model | Size | Response Time | Best For | Status |
|---|---|---|---|---|
| `gemma:2b` | 1.7 GB | **3.7s** | Default balance of speed and quality | âœ… Working |
| `gemma3:1b` | 815 MB | **2.5s** âš¡ | Quick interactions, simple tasks | âœ… Fastest |
| `llama3:latest` | 4.7 GB | **14.5s** | Complex reasoning, multi-step tasks | âœ… Working |
| `llama3.2:3b` | 2.0 GB | **20.3s** | Alternative mid-range model | âœ… Working |

> **Default:** `gemma:2b` â€” Best trade-off between speed and intelligence for everyday use.
>
> **Upgrade path:** When you need better code generation, pull `qwen2.5-coder:3b` via `ollama pull qwen2.5-coder:3b`.

### Switching Models at Runtime

```
llm use gemma3:1b           # Switch to fastest model
llm use llama3:latest       # Switch to smartest model
llm provider groq            # Switch to cloud (Groq) for max intelligence
```

---

## Persona System

Jarvis supports **switchable personality profiles** that bundle a personality style + TTS voice. Each persona modifies how Jarvis responds while preserving full functionality (command execution, shell tags, safety checks).

### Built-in Personas

| Persona | Key | Personality | Voice | Rate |
|---|---|---|---|---|
| ğŸ© **Witty JARVIS** | `witty` | British sophistication, dry humor, addresses you as "sir" | `en-GB-RyanNeural` | +10% |
| ğŸ’¼ **Professional** | `professional` | Concise, no-nonsense, zero fluff | `en-US-GuyNeural` | +15% |
| ğŸ˜Š **Friendly** | `friendly` | Warm, encouraging, casual language | `en-US-JennyNeural` | +12% |
| ğŸ”§ **Technical** | `technical` | Developer-focused, explains the "why", mentions edge cases | `en-US-AndrewNeural` | +8% |
| ğŸ¬ **Comic Relief** | `comic` | Over-the-top dramatic narration, treats every task like a movie trailer | `en-AU-WilliamNeural` | +5% |

> **Default persona:** Witty JARVIS â€” because every AI assistant should have a bit of personality.

### Persona Examples

**Witty JARVIS** responding to "open notepad":
> *"Ah, Notepad. The pinnacle of text editing technology. Opening it now, sir."*

**Professional** responding to "open notepad":
> *"Opening Notepad."*

**Comic Relief** responding to "open notepad":
> *"AND SO IT BEGINS... the legendary Notepad shall be SUMMONED! *thunderclap*"*

### Persona Commands

```
persona list              â€” List all available personas with active marker
persona set witty         â€” Switch to Witty JARVIS (also changes voice)
persona set professional  â€” Switch to Professional mode
persona status            â€” Show active persona, voice, and style
persona reset             â€” Reset to default (witty)
```

### Voice Commands

```
voice list                â€” Show all recommended voices with descriptions
voice set en-GB-RyanNeural â€” Manually override TTS voice
voice status              â€” Show current voice
```

### Available Voices

| Voice ID | Description |
|---|---|
| `en-GB-RyanNeural` | British Male (witty default) |
| `en-US-GuyNeural` | American Male (professional) |
| `en-US-JennyNeural` | American Female (friendly) |
| `en-US-AndrewNeural` | American Male (technical) |
| `en-AU-WilliamNeural` | Australian Male (comic) |
| `en-GB-SoniaNeural` | British Female |
| `en-US-AriaNeural` | American Female |
| `en-IN-NeerjaNeural` | Indian Female |
| `en-IN-PrabhatNeural` | Indian Male |

---

## Quickstart

### Prerequisites

- **Python 3.10+** â€” [Download](https://python.org/downloads/)
- **Ollama** â€” [Download](https://ollama.com) (for local LLM) â€” *recommended for getting started*
- **API Key** (optional, for cloud providers):
  - [Groq](https://console.groq.com/keys) (free, fastest cloud option)
  - [Gemini](https://aistudio.google.com/apikey) (free tier available)

### Setup (4 steps)

```powershell
# 1. Clone and enter the project
git clone https://github.com/your-username/Antigravity.git
cd Antigravity

# 2. Create virtual environment and install dependencies
python -m venv .venv
.venv\Scripts\activate
pip install -r Jarvis\requirements.txt

# 3. Install a local model via Ollama
ollama pull gemma:2b

# 4. Configure your environment
copy .env.example .env
notepad .env          # Set LLM_PROVIDER=ollama (default)
```

### Run

```powershell
.\run_jarvis.bat
```

Or manually:
```powershell
.venv\Scripts\activate
python -m Jarvis.main
```

---

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Jarvis App                          â”‚
â”‚                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Listener â”‚â”€â”€â”€â–¶â”‚ Orchestrator â”‚â”€â”€â”€â–¶â”‚    Brain      â”‚   â”‚
â”‚  â”‚ (Voice)  â”‚    â”‚  (Router)    â”‚â—€â”€â”€â”€â”‚ (Multi-LLM)   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚              â”‚    â”‚               â”‚   â”‚
â”‚       â”‚          â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚    â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚   â”‚
â”‚       â”‚          â”‚  â”‚ Tools  â”‚  â”‚    â”‚ â”‚  Persona  â”‚ â”‚   â”‚
â”‚       â”‚          â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚    â”‚ â”‚  Manager  â”‚ â”‚   â”‚
â”‚       â”‚          â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚    â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚   â”‚
â”‚       â”‚          â”‚  â”‚ Shell  â”‚  â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚       â”‚          â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚     â–²  â–²  â–²  â–²        â”‚
â”‚       â–¼          â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚  â”‚  â”‚  â”‚         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚             â”‚  â”‚  â”‚  â”” Ollama  â”‚
â”‚  â”‚  STT     â”‚    â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”     â”‚  â”‚  â””â”€â”€ Grok    â”‚
â”‚  â”‚(Whisper) â”‚    â”‚     TTS      â”‚     â”‚  â””â”€â”€â”€â”€â”€ Gemini  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚  (Edge-TTS)  â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€ Groq    â”‚
â”‚                  â”‚  per-persona â”‚                        â”‚
â”‚                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
â”‚                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚      PyQt6 UI (Window + Tray + Command Input)    â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### How It Works â€” The "Speak-to-Shell" Pipeline

```
  ğŸ¤ LISTEN          ğŸ§  THINK           âš¡ ACT             ğŸ”Š RESPOND
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Wake Word â”‚â”€â”€â”€â–¶â”‚ Orchestrator â”‚â”€â”€â”€â–¶â”‚   Execute    â”‚â”€â”€â”€â–¶â”‚   Edge-TTS   â”‚
â”‚ + Whisper â”‚    â”‚ classifies:  â”‚    â”‚  PowerShell  â”‚    â”‚  speaks back â”‚
â”‚  STT      â”‚    â”‚ Shell? LLM?  â”‚    â”‚  command     â”‚    â”‚  to user     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚ Meta-cmd?    â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

1. **Listen** â€” Porcupine detects "Jarvis" wake word â†’ audio captured â†’ Faster-Whisper transcribes to text
2. **Think** â€” Orchestrator classifies intent:
   - Direct shell command? â†’ Execute immediately
   - Meta-command (`llm status`, `persona set`)? â†’ Handle internally
   - Natural language? â†’ Send to Brain (LLM) with active persona's system prompt
3. **Act** â€” LLM response parsed for `[SHELL]...[/SHELL]` tags â†’ safety-checked â†’ executed in PowerShell
4. **Respond** â€” Text response spoken via Edge-TTS using the active persona's voice

### Project Structure

```
Antigravity/
â”œâ”€â”€ run_jarvis.bat              # One-click launcher
â”œâ”€â”€ .env                        # API keys & config (git-ignored)
â”œâ”€â”€ .env.example                # Reference config template
â”‚
â””â”€â”€ Jarvis/
    â”œâ”€â”€ main.py                 # App entry point â€” wires everything together
    â”œâ”€â”€ config.py               # Environment loading & constants
    â”œâ”€â”€ requirements.txt        # Python dependencies
    â”‚
    â”œâ”€â”€ core/
    â”‚   â”œâ”€â”€ brain.py            # Multi-provider LLM interface (Groq/Gemini/Grok/Ollama)
    â”‚   â”œâ”€â”€ orchestrator.py     # Command router & shell executor
    â”‚   â”œâ”€â”€ personas.py         # ğŸ†• Persona profiles & manager
    â”‚   â”œâ”€â”€ tools.py            # Sandboxed file system operations
    â”‚   â””â”€â”€ colors.py           # Terminal color utilities
    â”‚
    â”œâ”€â”€ input/
    â”‚   â”œâ”€â”€ listener.py         # Autonomous voice listener (wake word + recording)
    â”‚   â”œâ”€â”€ audio_capture.py    # Microphone audio capture
    â”‚   â””â”€â”€ transcribe_worker.py # Faster-Whisper STT worker thread
    â”‚
    â”œâ”€â”€ output/
    â”‚   â”œâ”€â”€ tts.py              # Edge-TTS text-to-speech (dynamic voice switching)
    â”‚   â””â”€â”€ visuals.py          # Thinking orb animation
    â”‚
    â”œâ”€â”€ ui/
    â”‚   â”œâ”€â”€ window.py           # Main PyQt6 window with command input panel
    â”‚   â””â”€â”€ tray.py             # System tray icon & menu
    â”‚
    â””â”€â”€ tests/
        â””â”€â”€ test_orchestrator.py # 19 unit tests (commands, personas, voices, safety)
```

---

## Configuration

All configuration is done via the `.env` file in the project root:

| Variable | Description | Default |
|---|---|---|
| `LLM_PROVIDER` | Active LLM backend | `ollama` |
| `OLLAMA_URL` | Ollama API endpoint | `http://localhost:11434/api/generate` |
| `OLLAMA_MODEL` | Default Ollama model | `gemma:2b` |
| `GROQ_API_KEY` | Groq Cloud API key | â€” |
| `GROQ_MODEL` | Groq model name | `llama-3.3-70b-versatile` |
| `GEMINI_API_KEY` | Google Gemini API key | â€” |
| `GEMINI_MODEL` | Gemini model name | `gemini-2.0-flash` |
| `GROK_API_KEY` | xAI Grok API key | â€” |
| `GROK_MODEL` | Grok model name | `grok-3-mini-fast` |
| `PORCUPINE_ACCESS_KEY` | Picovoice wake word key | â€” |
| `TTS_VOICE` | Default Edge-TTS voice (overridden by persona) | `en-US-GuyNeural` |
| `DEFAULT_PERSONA` | Starting persona on launch | `witty` |

### Provider Comparison

| Provider | Speed | Intelligence | Cost | Needs Internet | Best For |
|---|---|---|---|---|---|
| **Ollama** | Varies by model | Depends on model | Free | âŒ No | Privacy, offline use |
| **Groq** | âš¡ Fastest cloud | ğŸ§ ğŸ§ ğŸ§  (Llama 3.3 70B) | Free tier | âœ… Yes | Maximum speed |
| **Gemini** | Fast | ğŸ§ ğŸ§ ğŸ§  (Flash) | Free tier | âœ… Yes | Google ecosystem |
| **Grok** | Fast | ğŸ§ ğŸ§ ğŸ§  (xAI) | Paid | âœ… Yes | xAI users |

---

## Commands

### Voice Commands
Just say **"Jarvis"** followed by your request:
- *"Jarvis, what time is it?"*
- *"Jarvis, open notepad"*
- *"Jarvis, list files in my Downloads"*
- *"Jarvis, create a folder called Projects"*
- *"Jarvis, how much RAM am I using?"*

### Brain Control Commands

| Command | Description |
|---|---|
| `llm status` | Show provider, model, persona, and health |
| `llm models` | List available models for current provider |
| `llm provider <name>` | Switch provider (`groq`/`gemini`/`grok`/`ollama`) |
| `llm use <model>` | Switch model (e.g., `llm use gemma3:1b`) |
| `llm set temperature <0..2>` | Adjust creativity |
| `llm set max_tokens <int>` | Set response length limit |
| `llm set timeout <seconds>` | Set request timeout |
| `llm prompt show` | View active system prompt |
| `llm prompt set <text>` | Override system prompt |
| `llm reset` | Reset all settings, memory, and persona to defaults |
| `clear memory` | Clear conversation history |

### Persona Commands

| Command | Description |
|---|---|
| `persona list` | List all personas with active indicator |
| `persona set <name>` | Switch persona + auto-update voice |
| `persona status` | Show active persona, voice, and style |
| `persona reset` | Reset to default (Witty JARVIS) |

### Voice Commands

| Command | Description |
|---|---|
| `voice list` | Show all recommended Edge-TTS voices |
| `voice set <voice_id>` | Manually set TTS voice |
| `voice status` | Show current voice |

### Direct Shell Commands
These bypass the LLM and execute directly:

```
dir                           â€” List directory contents
git status                    â€” Check git status
pip list                      â€” List Python packages
ipconfig                      â€” Show network config
tasklist                      â€” List running processes
python script.py              â€” Run a Python script
```

---

## Safety

Jarvis includes safety guards for commands generated by the LLM:

| Blocked Pattern | Risk |
|---|---|
| `format c:` | Drive formatting |
| `rm -rf` / `Remove-Item -Recurse` | Recursive deletion |
| `diskpart` | Disk partitioning |
| `bcdedit` | Boot config modification |
| `reg delete` | Registry deletion |
| `shutdown` / `restart` | System shutdown |

If a dangerous command is detected in the LLM's response, Jarvis **blocks it** and shows a warning instead of executing.

---

## Terminal Color Scheme

| Color | Meaning | Tag |
|---|---|---|
| ğŸ”µ **Bright Cyan** | Your input (voice/typed) | `[YOU]` |
| ğŸŸ¢ **Bright Green** | AI responses | `[JARVIS]` |
| ğŸŸ¡ **Bright Yellow** | Shell commands being executed | `[EXEC]` |
| ğŸŸ£ **Magenta** | Shell command output | *(raw output)* |
| ğŸ”´ **Bright Red** | Errors | `[ERROR]` |
| ğŸ”µ **Bright Blue** | System info | `[INFO]` |
| âšª **Dark Gray** | Debug/timing info | *(dimmed)* |

---

## Development

### Running Tests
```powershell
# Run all 19 tests
.venv\Scripts\python.exe -m unittest Jarvis.tests.test_orchestrator -v
```

### Testing the Brain Directly
```python
from Jarvis.core.brain import Brain
brain = Brain()
response = brain.generate_response("Hello, what can you do?")
print(response)
```

### Testing Personas Programmatically
```python
from Jarvis.core.personas import PersonaManager
pm = PersonaManager()
pm.set_active("comic")
profile = pm.get_active()
print(f"Active: {profile.display_name} | Voice: {profile.voice}")
```

### Switching Providers Programmatically
```python
from Jarvis.core.brain import Brain
brain = Brain(provider="groq")       # Start with Groq
brain.set_provider("gemini")          # Switch to Gemini
brain.set_model("gemini-2.0-flash")   # Change model
brain.set_persona("professional")     # Switch persona
```

---

## Tech Stack

| Component | Technology |
|---|---|
| Language | Python 3.10+ |
| Desktop UI | PyQt6 |
| Wake Word | Porcupine (Picovoice) |
| Speech-to-Text | Faster-Whisper (local) |
| Text-to-Speech | Edge-TTS (Microsoft Neural) |
| LLM Providers | Ollama Â· Groq Â· Gemini Â· Grok |
| Local Models | gemma:2b Â· gemma3:1b Â· llama3 Â· llama3.2:3b |
| Persona System | 5 built-in profiles with auto-linked voices |
| Shell | PowerShell (Windows native) |
| Config | python-dotenv |

---

## Roadmap

### Phase 1: Stability & Polish *(Immediate)*

| Feature | Description | Status |
|---|---|---|
| Feedback Loop | Feed shell output back to LLM for verification/debugging | ğŸ”² Planned |
| Task-Aware Context | Conversation memory that remembers project context | ğŸ”² Planned |
| Error Auto-Recovery | LLM auto-suggests fixes when commands fail | ğŸ”² Planned |

### Phase 2: Better Models & Performance

| Feature | Description | Status |
|---|---|---|
| Model Auto-Selection | Route simple tasks to `gemma3:1b`, complex to `llama3` | ğŸ”² Planned |
| Streaming Responses | Token-by-token display for faster perceived speed | ğŸ”² Planned |
| Qwen3-Coder Support | Pull and integrate `qwen2.5-coder:3b` for code tasks | ğŸ”² Planned |

### Phase 3: Safety & Sandboxing

| Feature | Description | Status |
|---|---|---|
| Confirmation Mode | User-in-the-loop approval before executing LLM commands | ğŸ”² Planned |
| WSL Sandbox | Route risky commands to Windows Subsystem for Linux | ğŸ”² Planned |
| Command Audit Log | Log every executed command with timestamps | ğŸ”² Planned |

### Phase 4: Advanced Features

| Feature | Description | Status |
|---|---|---|
| Multi-file Editing | LLM generates code across multiple files | ğŸ”² Planned |
| Web UI | Browser-based interface alongside desktop app | ğŸ”² Planned |
| Plugin System | User-defined tools/commands the LLM can invoke | ğŸ”² Planned |
| Cross-platform | macOS / Linux support | ğŸ”² Planned |
| Conversation Persistence | Save/load conversation sessions | ğŸ”² Planned |

---

## License

This project is proprietary. All rights reserved.

---

<p align="center">
  Built with focus and intention.
</p>
